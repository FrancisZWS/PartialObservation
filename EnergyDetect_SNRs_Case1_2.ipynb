{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5881,"status":"ok","timestamp":1682125683441,"user":{"displayName":"Weishan Zhang","userId":"02899996824368835811"},"user_tz":240},"id":"WQhOO-fm0zHk","outputId":"199299b2-d78b-4e42-e9f1-07fff9e22052","scrolled":true},"outputs":[],"source":["'''Energydetection, updated Mar2023\n","'''\n","import torch\n","import os\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","import math\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.utils.data.distributed as TUDdistributed\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","from torch.autograd import Variable\n","import sys\n","from copy import deepcopy\n","import random\n","import collections\n","#from MobileNetV1_CriticalPath import Net\n","import matplotlib.pyplot as plt\n","import pandas as pd \n","# from sklearn.externals import joblib\n","from cnn_models import standalone_cnn\n","from cnn_models import decouple_cnn\n","from cnn_models import decouple_cnn_mod\n","\n","from pytz import timezone\n","TMZ = timezone('EST')\n","import datetime\n","import shutil\n","import time\n","\n","device = torch.device(\"cuda\")\n","use_cuda = True\n","criterion = nn.CrossEntropyLoss()\n","\n","random.seed(0) \n","\n","      \n","\n","def Dis_analysis(class_dir, tol_list):\n","  #idx_list: list of lists, global positions of locally observable bands for each node\n","  #coef_list: coef for averaging the param for each band, how many nodes are learning each certain band\n","    idx_list = []\n","    coef_list = [0]*len( tol_list )\n","    for i in range( len(class_dir) ): #Generating the mapping btw nodes and net_tol\n","        sub_idx_list = [] \n","        for j in class_dir[i]:\n","            for k in range( len(tol_list) ):\n","                if j == tol_list[k]:\n","                    sub_idx_list.append(k)\n","                    coef_list[k] += 1 \n","                    break\n","        idx_list.append(sub_idx_list)\n","    return idx_list, coef_list\n","\n","\n","\"\"\"626/720 dataset maker, each logit corresponds to the occupation of a single channel\"\"\"\n","class TotalDatasetMaker(Dataset):\n","    \"simple version that requires the user to edit input/label format elsewhere\"\n","    def __init__(self, db, label_list, transformFunc ):\n","        \"\"\"\n","        db: a list of input signal tensors, label_list: a list of data labels, corresponding to db.\n","        \"\"\"\n","        self.datasets = db\n","        self.label_list = label_list\n","        self.transformFunc = transformFunc\n","    def __getitem__(self, i):\n","        img = self.datasets[i]\n","        img = self.transformFunc(img)\n","        class_label = self.label_list[i]\n","        return img, class_label\n","\n","    def __len__(self):\n","        return len(self.label_list)\n","    \n","    \n","\"\"\"720 dataset maker, data looks like: each global channel occupation condition ==> \n","each node only learn from 'local' received signal(full size for each node) which is an element in the list of this condition \"\"\"\n","class NodeDatasetMaker(Dataset):\n","\n","    def __init__(self, db, label_list, node, class_dir, transformFunc ):\n","        \"\"\"\n","        db: a list of input signal tensors, label_list: a list of data labels, corresponding to db.\n","        node\n","        \"\"\"\n","        self.datasets = db\n","        self.label_list = label_list\n","        self.transformFunc = transformFunc\n","        self.chn_list = class_dir[node]\n","        self.node = node\n","    def __getitem__(self, i):\n","        img = self.datasets[i][self.node]\n","        img = self.transformFunc(img)\n","        class_label = self.label_list[i][self.chn_list]\n","        return img, class_label\n","\n","    def __len__(self):\n","        return len(self.label_list)\n","\n","def setDir(filepath):\n","  # if directory not exist, create. if directory already exist, empty it.\n","  if not os.path.exists(filepath):\n","    os.makedirs(filepath)\n","  else:\n","    print('Directory already exists')\n","    shutil.rmtree(filepath, ignore_errors = True)\n","    os.mkdir(filepath)\n","       \n","print('start')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"gDbfE3cy0zHy"},"outputs":[],"source":["def energy_detection_coop(thresh_list, class_dir, coef_list, test_loader):                             \n","#     '''Tests all nodes together, use TotalDatasetMaker, smarter distrib energy detection'''\n","#     '''thresh_list is the thresh for diff nodes, by default they're the same'''\n","    total = 0 #sum of occupation and emptiness\n","    test_loss = 0 \n","    total_ocp = 0 #occupied bands\n","    total_emp = 0 #empty bands\n","    correct = 0\n","    total_cmb = 0  #occupation combination\n","    correct_ocp = 0\n","    correct_emp = 0\n","    correct_cmb = 0\n","    coef = torch.tensor(coef_list)\n","\n","    for batchidx, (data, target) in enumerate(test_loader):\n","        #data, target = data.cuda(), target.cuda()\n","        #print(target.size())\n","#             data, target = Variable(data), Variable(target)\n","        target = Variable(target)\n","#             print('target size is:',target.size())\n","        output_manual = torch.zeros(target.shape) # manual global decision of CNN\n","        total_batch = float(torch.tensor(target.size()).prod()) #total num of channels in this batch\n","        total += total_batch\n","        total_cmb += float(target.size(0))\n","        total_ocp += float(target.sum())\n","        total_emp += float(total_batch - target.sum()) \n","        if (1-target).sum() != (torch.tensor(target.size()).prod() - target.sum()) : #Testing tensor dim =========\n","            print('show difference:',(1-target).sum(), total - target.sum())\n","            print('total ocp/emp calculation wrong')\n","        '''Above calculate the total number of channels detected and the ground truth number of occupation/emptiness'''\n","\n","        for idx in range(len(class_dir)): # apply fusion strategy on local detections\n","            node_power = torch.sum(1e7*data[idx], dim = -2)#  # get (batchsize*2) tensors of local channel power\n","            if idx == -1:\n","                print(node_power)\n","            localout = (node_power[:,0,class_dir[idx]]>thresh_list[idx]).float()\n","            output_manual[:,class_dir[idx]] = output_manual[:,class_dir[idx]].add(localout) \n","            # strategy: any node detects means occupation\n","\n","        output_manual = (output_manual.div_(coef) >0.49)\n","        correct_ocp += (output_manual*target).sum()\n","        correct_emp += ((~output_manual)*(1-target)).sum()\n","        correct_cmb += (~(output_manual^target.bool())).float().prod(1).sum() #use XNOR which is 'not+XOR'\n","#         print('correctocp',correct_ocp)\n","\n","    correct_tol = deepcopy(correct_ocp) + deepcopy(correct_emp) #just sum\n","    accuracy_tol = 100*correct_tol/total\n","    accuracy_pd = 100*correct_ocp/total_ocp\n","    accuracy_pfa = 100*correct_emp/total_emp\n","    accuracy_cmb = 100*correct_cmb/total_cmb\n","\n","#     print('++++++++++++++++++ Accuracy on global set: total: %d %%, combination: %d %%, PD: %d %%, PFA: %d %%' \\\n","#                                             % ( accuracy_tol, accuracy_cmb, accuracy_pd, 100-accuracy_pfa))\n","    Acc_set = (accuracy_tol.item(), accuracy_cmb.item(), accuracy_pd.item(), 100-accuracy_pfa.item())\n","    return Acc_set\n","\n","# ''' for energy detection'''\n","def energy_detection_coopSQR(thresh_list, class_dir, coef_list, test_loader):  \n","# squared input PSD                           \n","#     '''Tests all nodes together, use TotalDatasetMaker, smarter distrib energy detection'''\n","#     '''thresh_list is the thresh for diff nodes, by default they're the same'''\n","    total = 0 #sum of occupation and emptiness\n","    test_loss = 0 \n","    total_ocp = 0 #occupied bands\n","    total_emp = 0 #empty bands\n","    correct = 0\n","    total_cmb = 0  #occupation combination\n","    correct_ocp = 0\n","    correct_emp = 0\n","    correct_cmb = 0\n","    coef = torch.tensor(coef_list)\n","    for batchidx, (data, target) in enumerate(test_loader):\n","        #data, target = data.cuda(), target.cuda()\n","        #print(target.size())\n","#             data, target = Variable(data), Variable(target)\n","        target = Variable(target)\n","#             print('target size is:',target.size())\n","        output_manual = torch.zeros(target.shape) # manual global decision of CNN\n","        total_batch = float(torch.tensor(target.size()).prod()) #total num of channels in this batch\n","        total += total_batch\n","        total_cmb += float(target.size(0))\n","        total_ocp += float(target.sum())\n","        total_emp += float(total_batch - target.sum()) \n","        if (1-target).sum() != (torch.tensor(target.size()).prod() - target.sum()) : #Testing tensor dim =========\n","            print('show difference:',(1-target).sum(), total - target.sum())\n","            print('total ocp/emp calculation wrong')\n","        '''Above calculate the total number of channels detected and the ground truth number of occupation/emptiness'''\n","        for idx in range(len(class_dir)): # apply fusion strategy on local detections\n","            node_power = torch.sum((1e7*data[idx])**2, dim = -2)#  # get (batchsize*2) tensors of local channel power\n","            if idx == -1:\n","                print(node_power)\n","            localout = (node_power[:,0,class_dir[idx]]>thresh_list[idx]).float()\n","            output_manual[:,class_dir[idx]] = output_manual[:,class_dir[idx]].add(localout) \n","            # strategy: any node detects means occupation\n","        output_manual = (output_manual.div_(coef) >0.49)\n","        correct_ocp += (output_manual*target).sum()\n","        correct_emp += ((~output_manual)*(1-target)).sum()\n","        correct_cmb += (~(output_manual^target.bool())).float().prod(1).sum() #use XNOR which is 'not+XOR'\n","#         print('correctocp',correct_ocp)\n","    correct_tol = deepcopy(correct_ocp) + deepcopy(correct_emp) #just sum\n","    accuracy_tol = 100*correct_tol/total\n","    accuracy_pd = 100*correct_ocp/total_ocp\n","    accuracy_pfa = 100*correct_emp/total_emp\n","    accuracy_cmb = 100*correct_cmb/total_cmb\n","#     print('++++++++++++++++++ Accuracy on global set: total: %d %%, combination: %d %%, PD: %d %%, PFA: %d %%' \\                                          % ( accuracy_tol, accuracy_cmb, accuracy_pd, 100-accuracy_pfa))\n","    Acc_set = (accuracy_tol.item(), accuracy_cmb.item(), accuracy_pd.item(), 100-accuracy_pfa.item())\n","    return Acc_set\n","\n","def ROC_thresh(start, end, pts):\n","    return [start+i*(end-start)/pts for i in range(100)]\n","\n","thresh_dict = {\n","    0: ROC_thresh(10, 30 ,100),\n","    -2: ROC_thresh(15, 40 ,100),\n","    -4: ROC_thresh(20, 50 ,100),\n","    -6: ROC_thresh(40, 80 ,100),\n","    -8: ROC_thresh(70, 120 ,100),\n","    -10: ROC_thresh(100, 200 ,100),\n","    -12: ROC_thresh(170, 300 ,100),\n","    -14: ROC_thresh(300, 460 ,100),\n","    -16: ROC_thresh(450, 700 ,100),\n","    -18: ROC_thresh(450, 700 ,100),\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":58259,"status":"ok","timestamp":1682125888952,"user":{"displayName":"Weishan Zhang","userId":"02899996824368835811"},"user_tz":240},"id":"fNM2336HAUnc","outputId":"dfc3aba9-1d08-4b14-d1cd-3eaec881b6fa"},"outputs":[],"source":["for snr in [2,4,6,8,10,12,14,16]: #: #[12, 8 ]: #[12, 8, 14, 16, 20]\n","    roc_dots = 100\n","    volum = 10\n","    SNR= -1*snr \n","    nepoch = 1\n","    datadir = 'RefinedNewData/SNRs/230404_01_04/Data_SNR'+str(SNR)+'vol'+str(volum)+'.pth'\n","    datadir = 'RefinedNewData/SNRs/RandMod/Data_SNR'+str(SNR)+'vol1'+'.pth' # RandMod: revision dataset, PU mod varying (testing data only)\n","    # stage_dir='/SNRs/'#default for naming and directory\n","    stage_dir='/RandMod/' # PU mod varying (testing data only)\n","\n","    data_dict = torch.load(datadir)\n","    data_dict.keys()\n","\n","    db = data_dict['training data list']\n","    label_list = data_dict['training label list']\n","    db_te = data_dict['testing data list']\n","    label_list_te = data_dict['testing label list']\n","\n","    # Create models ==================================================================================================\n","    per_class_filter = 8\n","    #fms = 16 #size of final conv feature map\n","    shared_layers = 1\n","    class_dir=[[0, 3, 4, 19], [0, 1, 10, 4, 19], [1, 10, 4, 19, 5, 13], [1, 10, 2, 11, 14, 5, 13], [2, 11, 14, 5, 13, 6, 15, 17], [3, 4, 19, 7, 12, 18], [4, 19, 7, 12, 18, 8, 16], [4, 19, 5, 13, 8, 16], [5, 13, 8, 16, 9], [5, 13, 6, 15, 17, 9]]\n","\n","    tol_list = []\n","    for classi in class_dir:\n","        tol_list += classi\n","    tol_list = list( set(tol_list) )\n","    tol_list.sort()\n","\n","    print(class_dir)\n","    print(tol_list)\n","\n","    # get coef \n","    idx_list, coef_list = Dis_analysis(class_dir, tol_list)\n","    print(idx_list, coef_list)\n","\n","\n","    db_tr_list = []\n","    for idx in range(len(class_dir)):# train datasets are more complex\n","        db_tr_list.append(NodeDatasetMaker( db, label_list, idx, class_dir, transforms.Compose([ ]) ))\n","    db_te_1 = TotalDatasetMaker( db_te, label_list_te, transforms.Compose([ ]) )\n","\n","    train_loader_list = []\n","    for idx in range(len(class_dir)):# trainloaders are more complex\n","        train_loader_list.append(DataLoader(db_tr_list[idx], batch_size=200, shuffle=True, num_workers=4, pin_memory=True))\n","    # tol_train_loader = DataLoader(tol_trainsets, batch_size=100, shuffle=False, num_workers=0, pin_memory=True)\n","    tol_test_loader = DataLoader(db_te_1, batch_size=1024, shuffle=False, num_workers=4, pin_memory=True)\n","\n","    now=datetime.datetime.now(TMZ) #time watermark\n","    time_watermark = now.strftime('%y%m%d_%H_%M')\n","    print('model watermark',time_watermark)\n","    address_model = 'Saved_Models/EnergyDetect'+stage_dir+str(SNR)+'dBVol'+str(volum)+'_'+time_watermark+'/' #root dir for saved models\n","    #child dir nbamed by time_watermark\n","    setDir(address_model)\n","   \n","    print('Models saved to dir:\\n', address_model)\n","    name0 = 'EnergyDetect'+'_SNR'+str(SNR)+'vol'+str(volum) # common part of DNN node names\n","\n","\n","    # ROC  ==================================================================================================\n","    '''ROC module of current standalone model, saved in pd2 and pfa2'''\n","    # net_list = Split_MDLT(net_list, net_tol, idx_list, coef_list,  shared_layers, class_dir) # if merged net better, do this before ROC\n","    pd2= []\n","    pfa2 = []\n","    Acc2 = []\n","\n","    for thresh_val in thresh_dict[SNR]:  \n","        print('threshold:', thresh_val)\n","        thresh_list = [thresh_val]*len(class_dir)\n","        testing=energy_detection_coop(thresh_list, class_dir, coef_list, tol_test_loader)\n","        print('thresh:', thresh_val, 'accuracy:',testing[0], 'PD:',testing[2], 'PFA:',testing[3])\n","\n","        pd2.append(testing[2])\n","        pfa2.append(testing[3])\n","        Acc2.append(testing[0])\n","\n","    plt.title(\"ROC of EnergyDetect\"+ \" method in SNR=\"+str(SNR)+\"dB\")\n","    l2, = plt.plot(pfa2, pd2, color='green', label='Transformer')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    dfroc = pd.DataFrame() # save statics to excel\n","    # df1['acc_old'] = xx\n","    dfroc['PFA'] = pfa2\n","    dfroc['PD'] = pd2\n","    dfroc['Acc'] = Acc2\n","    with pd.ExcelWriter(address_model + \"ROC_SNR\"+str(SNR)+\".xlsx\", mode='w') as writer:  #mode was 'a'\n","      dfroc.to_excel(writer, sheet_name='EnergyDetect')\n","    print('ROC in Excel saved to:', address_model + \"ROC_SNR\"+str(SNR)+\".xlsx\")\n","\n","    ROC_dict = {\n","        'pd':pd2,\n","        'pfa':pfa2,\n","        'Acc':Acc2\n","    }\n","    torch.save(ROC_dict, address_model+'EnergyDetect'+'ROC.pth')\n","    print('ROC in Lists saved to:', address_model+'EnergyDetect'+'ROC.pth')\n"]}],"metadata":{"accelerator":"GPU","celltoolbar":"Tags","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
